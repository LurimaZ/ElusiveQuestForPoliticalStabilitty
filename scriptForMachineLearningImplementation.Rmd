---
title: "scriptForMachineLearningImplementation"
author: "Adrien Ratsimbaharison"
date: "May 21, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This machine learning script is based on the "Practical guide to implement machine learning with CARET in R" suggested by Saurav Kaushik in the Analytics Vidhya website: https://www.analyticsvidhya.com/blog/2016/12/practical-guide-to-implement-machine-learning-with-caret-package-in-r-with-practice-problem/ (December 8, 2016).   

The Caret package solves many problems in the implementation of machine learning process, and make it much easier to execute, even for beginners like the autors of this book.
As Kaushik puts it, "This package [i.e., CARET package] alone is all you need to know for solve almost any supervised machine learning problem. It provides a uniform interface to several machine learning algorithms and standardizes various other tasks such as Data splitting, Pre-processing, Feature selection, Variable importance estimation, etc."

The different steps suggested by Saurav Kaushik include the following:  

1) Getting started with loading the package and looking at the data
2) Pre-processing the data using Caret
3) Splitting the data using Caret
4) Feature selection using Caret
5) Training models using Caret
6) Parameter tuning using Caret
7) Variable importance estimation using Caret
8) Making predictions using Caret


## 1. Getting started with loading the package and looking at the data

Installing and loading the Caret package and its dependencies:

```{r message=FALSE, warning=FALSE, include=FALSE}
# Intalling the caret package if it is not already installed

# install.packages("caret", dependencies = c("Depends", "Suggests"))

# loading the caret package and other required packages:
library(caret)
library(dplyr)

```

Reading the data in R and looking at its structure

```{r}
# Reading the data
train <- read.csv("WGI2popDevIneqPovRegimeConflict2.csv", stringsAsFactors = TRUE)

# Looking at its structure and summary
str(train)

# correcting the types of some variables that will be used in the models
train$population <- as.numeric(train$population)
train$inverse_pr <- as.numeric(train$inverse_pr)
train$inverse_cl <- as.numeric(train$inverse_cl)
train$conflictHistory <- as.factor(train$conflictHistory)

```


Defining the problem:

In this problem we want to predict the classification of countries into two categories (either as "stable" or "unstable"), based on the following groups of factors or indicators:

- World Governance Indicators,
- Demographic and economic indicators,
- Regime type indicators,
- Conflict history.



## 2. Pre-processing the data using Caret

First, we need to remove the variables that are not significant for the machine learning implementation, such as the identification codes ("country", "M49Code", "iso2c", "iso3c"), and the codes that are redundant, such as "pr", "cl", "sum", "mean" (these codes will be replaced by their inverse) and "stabilityCategory", "stabilityCategory", "devCategory", "status", 

```{r}
train <- select(train, stabilityCategory2, corruptionControl, governmentEffectiveness, regulatoryQuality, ruleOfLaw, voiceAndAccountability, population, GNIperCapita, GDPannualGrowthRate, HDI, GINI, povertyHeadCount, inverse_pr, inverse_cl, inverse_mean, politicalChangeFH, conflictHistory, region, subregion)

```
Next, we check and locate the missing values.

```{r}
sum(is.na(train))
summary(train)

```

The missing values are concentrated in the following variables: "region" and "subregion". In identifying the observations without "region" and "subregion", we found out that they do not have "country" either. Therefore, we decided to remove them all.

```{r}

# removing the observation without "region" and "subregion"
train <- na.omit(train)
sum(is.na(train))
summary(train) # showing that there are no more missing value in the train dataset.

```

In addition, the caret package allows us to pre-process our data, by scaling and centering the numerical variables. The importance of scaling and centering the numerical variables is always emphasized by many data scientists to improve model performance.(See, for instance, Bowne-Anderson, H. (2016, April 26). Preprocessing in Data Science (Part 1). Retrieved May 23, 2019, from DataCamp Community website: https://www.datacamp.com/community/tutorials/preprocessing-in-data-science-part-1-centering-scaling-and-knn)


```{r}
# Centering and scaling numerical variables

preProcValues <- preProcess(train, method = c("center","scale")) # since we already remove the incomplete cases, we don't need to include in this preprocessing procedure the kNN imputation

library('RANN')
train_processed <- predict(preProcValues, train)

```

Finally, in addition to the centering and scaling, we can "one hot encoding" in Caret to create dummy variables for each level of a categorical variable.

```{r}
# Before creating the dummy variables for each categorical variable, we need to convert the outcome variable to numeric
train_processed$stabilityCategory2 <-ifelse(train_processed$stabilityCategory2=='unstable',0,1)


# Creating dummy variables using "one hot encoding" by converting every categorical variable to numerical using dummy variables
dmy <- dummyVars(" ~ .", data = train_processed,fullRank = T)
train_transformed <- data.frame(predict(dmy, newdata = train_processed))

#Checking the structure of transformed train file
str(train_transformed)

#Converting the dependent variable back to categorical
train_transformed$stabilityCategory2 <-as.factor(train_transformed$stabilityCategory2)

```


## 3. Splitting the data using Caret

Since the dataset was initially arranged in a country-year format, it is a good idea to randomize the rows before splitting the dataset into trainSet and testSet. 

```{r}
# Randomizing the dataset
set.seed(123)
rows <- sample(nrow(train_transformed))
train_transformed <- train_transformed[rows,]

#Spliting dataset into trainSet and testSet based on outcome with a ratio of 75% and 25%, using createDataPartition in Caret
index <- createDataPartition(train_transformed$stabilityCategory2, p=0.75, list=FALSE)
trainSet <- train_transformed[index,]
testSet <- train_transformed[-index,]

#Checking the structure of trainSet
str(trainSet)

```



## 4. Feature selection using Caret

The feature selection, which is a crucial part of machine learning, is made easy by Caret. The "recursive feature elimination" or "rfe" function in Caret is used to find the best subset of features to be included in the models.

```{r}
# Feature selection using rfe in caret
control <- rfeControl(functions = rfFuncs,
                   method = "repeatedcv",
                   repeats = 3,
                   verbose = FALSE)
outcomeName<-'stabilityCategory2'
predictors<-names(trainSet)[!names(trainSet) %in% outcomeName]
stability_Pred_Profile <- rfe(trainSet[,predictors], trainSet[,outcomeName],
                      rfeControl = control)
stability_Pred_Profile

```

The result of the feature selection using "rfe" function in Caret is as follows:


Recursive feature selection

Outer resampling method: Cross-Validated (10 fold, repeated 3 times) 

Resampling performance over subset size:

The top 5 variables (out of 16):
   population, ruleOfLaw, corruptionControl, conflictHistory, GNIperCapita


## 5. Training models using Caret

Caret provides a large number of algorithms with similar syntax. Following Kaushik's practical guide, we will apply the following: GBM, Random forest, Neural net and Logistic regression.

```{r}
model_gbm<-train(trainSet[,predictors],trainSet[,outcomeName],method='gbm')
model_rf<-train(trainSet[,predictors],trainSet[,outcomeName],method='rf')
model_nnet<-train(trainSet[,predictors],trainSet[,outcomeName],method='nnet')
model_glm<-train(trainSet[,predictors],trainSet[,outcomeName],method='glm')
```



## 6. Parameter tuning using Caret (Skipped)



## 7. Variable importance estimation using Caret

We can also check the variable importance estimates in Caret by using the "varImp" function" for any model.

### 7.1 Variable importance for GBM

```{r}
# Checking variable importance for GBM
# Variable Importance
varImp(object=model_gbm)


#Plotting Varianle importance for GBM
plot(varImp(object=model_gbm),main="GBM - Variable Importance")

```

### 7.2 Variable importance for RF

```{r}
#Checking variable importance for RF
varImp(object=model_rf)
#rf variable importance


#Plotting Varianle importance for Random Forest
plot(varImp(object=model_rf),main="RF - Variable Importance")

```


### 7.3 Variable importance for NNET

```{r}
#Checking variable importance for NNET
varImp(object=model_nnet)
#nnet variable importance

#Plotting Variable importance for Neural Network
plot(varImp(object=model_nnet),main="NNET - Variable Importance")

```

### 7.4 Variable importance for GLM

```{r}
#Checking variable importance for GLM
varImp(object=model_glm)
#glm variable importance

#Plotting Variable importance for GLM
plot(varImp(object=model_glm),main="GLM - Variable Importance")

```

## 8. Making predictions using Caret

```{r}
#Predictions with gbm
predictions_gbm <-predict.train(object=model_gbm,testSet[,predictors],type="raw")
table(predictions_gbm)

confusionMatrix(predictions_gbm,testSet[,outcomeName])

```


```{r}
#Predictions with rf
predictions_rf <-predict.train(object=model_rf,testSet[,predictors],type="raw")
table(predictions_rf)

confusionMatrix(predictions_rf,testSet[,outcomeName])

```

## Conclusion

Random forest allows to predict stability and instability with an accuracy of 92.8% (nearly 93%).

Result:
 Accuracy : 0.9283        
                 95% CI : (0.91, 0.9439)
    No Information Rate : 0.5437        
    P-Value [Acc > NIR] : <2e-16        
                                        
                  Kappa : 0.8559        
                                        
 Mcnemar's Test P-Value : 0.1822        
                                        
            Sensitivity : 0.9353        
            Specificity : 0.9225
            
